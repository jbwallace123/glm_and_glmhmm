{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "First, you must clone the `ssm` repository and install all of the dependencies. The `ssm` package we are using can be found, along with installation instructions, [here](https://github.com/lindermanlab/ssm.git). \n",
    "\n",
    "The line `import ssm` imports the package for use. Here, we have also imported a few other packages for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sglm import hmmUtils, utils, qUtils\n",
    "import ssm\n",
    "\n",
    "npr.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a. Import your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = pd.read_csv(r'C:\\Users\\janet\\Documents\\Behavior_samp_data\\FreelyMoving_6nback_021024_wDOB_wrecordDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = '80-20'\n",
    "ages = [1, 2, 3] # 1: 2 months, 2: 4 months, 3: 6 months, 4: 12 months\n",
    "trial_based = 1\n",
    "filtered_data = data_[(data_['Condition'] == probs) & (data_['Age_Group'].isin(ages)) & (data_['Trial_based'] == trial_based)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choice as -1 or 1\n",
    "filtered_data.loc[:, '1_Port'] = filtered_data['1_Port'].replace(0, -1)\n",
    "filtered_data.loc[:, '2_Port'] = filtered_data['2_Port'].replace(0, -1)\n",
    "filtered_data.loc[:, '3_Port'] = filtered_data['3_Port'].replace(0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janet\\AppData\\Local\\Temp\\ipykernel_8884\\1374730130.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.loc[:, '1_ChoiceReward'] = filtered_data['1_Port'] * filtered_data['1_Reward']\n",
      "C:\\Users\\janet\\AppData\\Local\\Temp\\ipykernel_8884\\1374730130.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.loc[:, '2_ChoiceReward'] = filtered_data['2_Port'] * filtered_data['2_Reward']\n",
      "C:\\Users\\janet\\AppData\\Local\\Temp\\ipykernel_8884\\1374730130.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.loc[:, '3_ChoiceReward'] = filtered_data['3_Port'] * filtered_data['3_Reward']\n"
     ]
    }
   ],
   "source": [
    "#add columns for interaction between reward and choice\n",
    "filtered_data.loc[:, '1_ChoiceReward'] = filtered_data['1_Port'] * filtered_data['1_Reward']\n",
    "filtered_data.loc[:, '2_ChoiceReward'] = filtered_data['2_Port'] * filtered_data['2_Reward']\n",
    "filtered_data.loc[:, '3_ChoiceReward'] = filtered_data['3_Port'] * filtered_data['3_Reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add up animals in unique age groups\n",
    "age_group = filtered_data.groupby('Age_Group')\n",
    "\n",
    "#add up in each age group\n",
    "age_group_counts = age_group['Mouse ID'].unique()\n",
    "age_group_counts = age_group_counts.apply(lambda x: len(x))\n",
    "age_group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_counts = age_group['Mouse ID'].unique()\n",
    "age_group_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input Driven Observations\n",
    "We create a HMM with input-driven observations and 'standard' (stationary) transitions with the following line:  \n",
    "```python\n",
    "        ssm.HMM(num_states, obs_dim, input_dim, observations=\"input_driven_obs\", observation_kwargs=dict(C=num_categories), transitions=\"standard\")\n",
    "```\n",
    "\n",
    "As in Ashwood et al. (2020), we are going to model an animal's binary choice data during a decision-making task, so we will set `num_categories=2` because the animal only has two options available to it. We will also set `obs_dim = 1` because the dimensionality of the observation data is 1 (if we were also modeling, for example, the binned reaction time of the animal, we could set `obs_dim = 2`).  For the sake of simplicity, we will assume that an animal's choice in a particular state is only affected by the external stimulus associated with that particular trial, and its innate choice bias. Thus, we will set `input_dim = 2` and we will simulate input data that resembles sequences of stimuli in what follows.  In Ashwood et al. (2020), they found that many mice used 3 decision-making states when performing 2AFC tasks. We will, thus, set `num_states = 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Set up your model and initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inputs\n",
    "num_states = [4] # number of discrete states, can be a single value or list\n",
    "obs_dim =  1 # number of observed dimensions, 1 for just reward, 2 if you had something like reaction time\n",
    "num_categories = 2 # number of categories for the output\n",
    "\n",
    "# set sigma and alpha for the prior on the weights, set kappa for \"sticky\" transitions\n",
    "prior_sigma = 2\n",
    "prior_alpha = 2\n",
    "#kappa = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Option 1 - Data and param set up for global fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = '80-20'\n",
    "train_split = 0.80\n",
    "seed = np.random.randint(1000)\n",
    "\n",
    "# Get train/test session IDs\n",
    "\n",
    "train_ids, test_ids = train_test_split(filtered_data['Session ID'].unique(), \n",
    "                                      train_size=train_split, random_state=seed)\n",
    "\n",
    "print('You have {} training sessions and {} test sessions.'.format(len(train_ids), len(test_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train_data list of dataframes for each session\n",
    "train_data = [filtered_data[filtered_data['Session ID'] == i] for i in train_ids]\n",
    "test_data = [filtered_data[filtered_data['Session ID'] == i] for i in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting specific columns and creating variables for model input GLOBAL\n",
    "x_cols = ['1_Reward', '2_Reward', '3_Reward', '1_Port', '2_Port', '3_Port', '1_ChoiceReward', '2_ChoiceReward', '3_ChoiceReward']\n",
    "\n",
    "# loop through train_data and test_data to get x and y data\n",
    "train_data_x = [i[x_cols].values for i in train_data]\n",
    "test_data_x = [i[x_cols].values for i in test_data]\n",
    "\n",
    "# number of trials in each train_data_x and test_data_x\n",
    "train_data_sessions = [len(i) for i in train_data_x]\n",
    "test_data_sessions = [len(i) for i in test_data_x]\n",
    "\n",
    "num_trials_per_train_sess = len(train_data_sessions)\n",
    "num_trials_per_test_sess = len(test_data_sessions)\n",
    "\n",
    "# Extract 'Decision' from train_data and test_data\n",
    "choices = [i['Decision'] for i in train_data]\n",
    "test_data_y = [i['Decision'] for i in test_data]\n",
    "\n",
    "# Reshape and convert data to integer type\n",
    "choices = [i['Decision'].values.reshape(-1, 1).astype(int) for i in train_data]\n",
    "test_data_y = [i['Decision'].values.reshape(-1, 1).astype(int) for i in test_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. (Option 1) - Fit the model globally with cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = \"input_driven_obs\"\n",
    "transitions = \"standard\"\n",
    "iters = 500\n",
    "\n",
    "global_model_list, global_ll_list, global_train_scores, global_test_scores = hmmUtils.global_fit(\n",
    "    train_data_x, choices, num_states, obs_dim, observations, num_categories, prior_sigma, transitions, prior_alpha, iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_weights = global_model_list[0].observations.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save stationary model list, train and test scores, and LL list\n",
    "import pickle\n",
    "\n",
    "model_params = {'num_states': num_states,\n",
    "                'obs_dim': obs_dim,\n",
    "                'num_categories': num_categories,\n",
    "                'prior_sigma': prior_sigma,\n",
    "                'prior_alpha': prior_alpha,\n",
    "                'observations': observations,\n",
    "                'transitions': transitions,\n",
    "                'x_cols': x_cols,\n",
    "                'data_filter': 'age_group:3, probs:80-20, trial_based:1',\n",
    "                'notes': \"used 3 nback data, 80-20 prob, 80-20 split, reward is 0-1, choice is -1-1, global fit\"}\n",
    "\n",
    "data_splits = {'train_split': train_split,\n",
    "               'train_ids': train_ids,\n",
    "               'test_ids': test_ids,\n",
    "               }\n",
    "\n",
    "#create dictionary for pickle\n",
    "model_dict = {'model_params' : model_params,\n",
    "                'data_splits': data_splits,\n",
    "                   'model_list': global_model_list,\n",
    "                   'model_train_scores': global_train_scores,\n",
    "                   'model_test_scores': global_test_scores,\n",
    "                   'model_ll_list': global_ll_list, \n",
    "                   'model_weights': global_weights}\n",
    "\n",
    "#save dictionary in pickle file\n",
    "save_dir = r'C:\\Users\\janet\\Documents\\Behavior_samp_data\\models'\n",
    "pickle.dump(model_dict, open(os.path.join(save_dir, 'global_fit_' + f'{num_states}state.pkl'), 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Option 2 - Data and param set up for individual fits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create separate datasets for each mouse\n",
    "mice = filtered_data['Mouse ID'].unique()\n",
    "\n",
    "mouse_dfs = []\n",
    "\n",
    "for mouse in mice:\n",
    "    mouse_data = filtered_data[filtered_data['Mouse ID'] == mouse]\n",
    "    mouse_dfs.append({'mouse': mouse, 'data': mouse_data})    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split each mouse's data into train and test sets\n",
    "train_split = 0.8\n",
    "seed = np.random.randint(1000)\n",
    "\n",
    "#get train and test session IDs\n",
    "train_ids = []\n",
    "test_ids = []\n",
    "splits = []\n",
    "\n",
    "for mouse in mouse_dfs:\n",
    "    mouse_train, mouse_test = train_test_split(mouse['data']['Session ID'].unique(), \n",
    "                                               train_size=train_split, random_state=seed)\n",
    "    train_ids.append(mouse_train)\n",
    "    test_ids.append(mouse_test)\n",
    "    splits.append({'mouse': mouse['mouse'], 'train': len(mouse_train), 'test': len(mouse_test)})\n",
    "\n",
    "#split data\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "\n",
    "for i, mouse in enumerate(mouse_dfs):\n",
    "    train_data.append({'mouse': mouse, 'data': [[mouse['data'][mouse['data']['Session ID'] == ii]] for ii in train_ids[i]]})\n",
    "    test_data.append({'mouse': mouse, 'data': [[mouse['data'][mouse['data']['Session ID'] == ii]] for ii in test_ids[i]]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping through each mouse to extract data and set model inputs - INDIVIDUAL\n",
    "x_cols = ['1_Reward', '2_Reward', '3_Reward', '1_Port', '2_Port', '3_Port', '1_ChoiceReward', '2_ChoiceReward', '3_ChoiceReward']\n",
    "\n",
    "train_data_x, test_data_x, train_choices, test_choices, train_data_trials, test_data_trials = hmmUtils.create_animal_datalist(train_data, test_data, x_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e. Option 2 - Fit the model across individual animals with cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = \"input_driven_obs\"\n",
    "transitions = \"standard\"\n",
    "iters = 500\n",
    "\n",
    "mouse_model_list, mouse_ll_list, mouse_train_scores, mouse_test_scores = hmmUtils.animal_fit(\n",
    "    train_data_x, train_choices, num_states, obs_dim, observations, num_categories, prior_sigma, transitions, prior_alpha, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loop through each mouse and find generative weights and append to list\n",
    "mouse_weights = []\n",
    "for i in range(len(mouse_model_list)):\n",
    "    mouse_weights.append({'mouse': train_data_x[i]['mouse'], 'weights': mouse_model_list[i]['glmhmm'].observations.params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save stationary model list, train and test scores, and LL list\n",
    "import pickle\n",
    "\n",
    "model_params = {'num_states': num_states,\n",
    "                'obs_dim': obs_dim,\n",
    "                'num_categories': num_categories,\n",
    "                'prior_sigma': prior_sigma,\n",
    "                'prior_alpha': prior_alpha,\n",
    "                'observations': observations,\n",
    "                'transitions': transitions,\n",
    "                'x_cols': x_cols,\n",
    "                'data_filter': 'age_group:3, probs:80-20, trial_based:1',\n",
    "                'notes': \"used 3 nback data, 80-20 prob, 80-20 split, reward is 0-1, choice is -1-1, animal fits\"}\n",
    "\n",
    "data_splits = {'train_split': train_split,\n",
    "               'train_ids': train_ids,\n",
    "               'test_ids': test_ids,\n",
    "               'splits': splits}\n",
    "\n",
    "#create dictionary for pickle\n",
    "model_dict = {'model_params' : model_params,\n",
    "                'data_splits': data_splits,\n",
    "                   'model_list': mouse_model_list,\n",
    "                   'model_train_scores': mouse_train_scores,\n",
    "                   'model_test_scores': mouse_test_scores,\n",
    "                   'model_ll_list': mouse_ll_list, \n",
    "                   'weights': mouse_weights}\n",
    "\n",
    "#save dictionary in pickle file\n",
    "save_dir = r'C:\\Users\\janet\\Documents\\Behavior_samp_data\\models'\n",
    "pickle.dump(model_dict, open(os.path.join(save_dir, 'animal_fits_'+f'{num_states}state.pkl'), 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the results - here, we will plot the GLM weights for the global fit and the individual fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states_2plot = num_states[-1]\n",
    "\n",
    "cols = ['#ff7f00', '#4daf4a', '#377eb8', '#e41a1c']\n",
    "\n",
    "if num_states_2plot == 1:\n",
    "    # Plot the GLM weights for each input regressor for each mouse \n",
    "    fig = plt.figure(figsize=(7, 2.5), dpi=80, facecolor='w', edgecolor='k')\n",
    "    for i in range(len(mouse_weights)):\n",
    "        for j in range(num_states_2plot):\n",
    "            plt.plot(-mouse_weights[i]['weights'][j,0,:], lw=2,\n",
    "                color=cols[j], marker = 'o', markersize = 5)\n",
    "            plt.plot(-global_weights[j,0,:], lw=2, color='black', linestyle='--')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xticks(np.arange(len(x_cols)), x_cols, rotation=45, fontsize = 10)\n",
    "    plt.ylabel(\"GLM weight\", fontsize = 15)\n",
    "    plt.xlabel(\"Inputs\", fontsize = 15)\n",
    "    plt.xlim((0, len(x_cols)))\n",
    "    plt.title('HMM fits - ' + f'{num_states_2plot}' + 'state')\n",
    "else:\n",
    "    ## Plot the GLM weights for each input regressor for each mouse use subplots for each state\n",
    "    fig, axs = plt.subplots(num_states_2plot, 1, figsize=(12, 18), dpi=80, facecolor='w', edgecolor='k')\n",
    "    axs = axs.ravel()\n",
    "    for i in range(len(mouse_weights)):\n",
    "        for j in range(num_states_2plot):\n",
    "            axs[j].plot(-mouse_weights[i]['weights'][j,0,:], lw=2,\n",
    "                color=cols[j], marker = 'o', markersize = 5)\n",
    "            axs[j].plot(-global_weights[j,0,:], lw=2, color='black', linestyle='--')\n",
    "            axs[j].set_title('State' + str(j + 1), fontsize = 15)\n",
    "            axs[j].set_ylabel(\"GLM weight\", fontsize = 15)\n",
    "            axs[j].set_xlabel(\"Inputs\", fontsize = 15)\n",
    "            axs[j].set_xlim((0, len(x_cols)))\n",
    "            axs[j].set_xticks(np.arange(len(x_cols)))\n",
    "            axs[j].set_xticklabels(x_cols, rotation=45, fontsize = 10)\n",
    "    plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have trained the models, we will compare them with some QC metrics and plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, lets load our models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load previously saved model\n",
    "import pickle\n",
    "save_dir = r'C:\\Users\\janet\\Documents\\Behavior_samp_data\\models'\n",
    "\n",
    "global_model_1 = pickle.load(open(os.path.join(save_dir, '1-state', 'global_fit_[1]state.pkl'), 'rb'))\n",
    "global_model_2 = pickle.load(open(os.path.join(save_dir, '2-state', 'global_fit_[2]state.pkl'), 'rb'))\n",
    "global_model_3 = pickle.load(open(os.path.join(save_dir, '3-state', 'global_fit_[3]state.pkl'), 'rb'))\n",
    "global_model_4 = pickle.load(open(os.path.join(save_dir, '4-state', 'global_fit_[4]state.pkl'), 'rb'))\n",
    "\n",
    "animal_model_1 = pickle.load(open(os.path.join(save_dir, '1-state', 'animal_fits_[1]state.pkl'), 'rb'))\n",
    "animal_model_2 = pickle.load(open(os.path.join(save_dir, '2-state', 'animal_fits_[2]state.pkl'), 'rb'))\n",
    "animal_model_3 = pickle.load(open(os.path.join(save_dir, '3-state', 'animal_fits_[3]state.pkl'), 'rb'))\n",
    "animal_model_4 = pickle.load(open(os.path.join(save_dir, '4-state', 'animal_fits_[4]state.pkl'), 'rb'))\n",
    "\n",
    "#Put models in list for easy access\n",
    "global_models = [global_model_1, global_model_2, global_model_3, global_model_4]\n",
    "animal_models = [animal_model_1, animal_model_2, animal_model_3, animal_model_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will normalize the test log likelihoods and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through global models and determine normalized test LL\n",
    "global_test_ll = []\n",
    "for i in range(len(global_models)):\n",
    "    num_states = global_models[i]['model_params']['num_states']\n",
    "    sessions = global_models[i]['data_splits']['test_ids']\n",
    "    sess_df = filtered_data[filtered_data['Session ID'].isin(sessions)]\n",
    "    trials = len(sess_df)\n",
    "\n",
    "    test_choices = sess_df['Decision'].to_numpy().reshape(-1, 1).astype(int)\n",
    "    x_cols = global_models[i]['model_params']['x_cols']\n",
    "    test_inpts = sess_df[x_cols].to_numpy()\n",
    "    test_ll = global_models[i]['model_list'][0].log_likelihood(test_choices, test_inpts)\n",
    "    norm_ll = [test_ll/trials]\n",
    "    global_test_ll.append({'num_states': num_states, 'norm_ll': norm_ll})\n",
    "\n",
    "    #Plot normalized test LL for each global model against number of states\n",
    "num_states_list = [1, 2, 3, 4]\n",
    "\n",
    "fig = plt.figure(figsize=(4, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "norm_ll_vals_list = []\n",
    "delta_ll_vals_list = []\n",
    "\n",
    "for i in range(len(global_test_ll)):\n",
    "    norm_ll_vals = global_test_ll[i]['norm_ll'][0]\n",
    "    norm_ll_vals_list.append(norm_ll_vals)\n",
    "\n",
    "for s in range(len(global_test_ll)):\n",
    "    delta_vals = norm_ll_vals_list[s] - norm_ll_vals_list[0]\n",
    "    delta_ll_vals_list.append(delta_vals)\n",
    "\n",
    "plt.plot(num_states_list, delta_ll_vals_list, marker = 'o', markersize = 5, lw=2)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"$\\Delta$NLL\", fontsize = 15)\n",
    "plt.xlabel(\"num_states\", fontsize = 15)\n",
    "plt.xticks(np.arange(1, 5))\n",
    "plt.title('Global fits - normalized test LL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_test_ll = []\n",
    "\n",
    "for i in range(len(animal_models)):\n",
    "    num_states = animal_models[i]['model_params']['num_states']\n",
    "    x_cols = animal_models[i]['model_params']['x_cols']\n",
    "    for j, mouse in enumerate(animal_models[i]['model_list']):\n",
    "        sessions = animal_models[i]['data_splits']['test_ids'][0:]\n",
    "        sess_list = []  \n",
    "        test_choices = []  \n",
    "        trials = []  \n",
    "        test_inpts = []  \n",
    "        #create dataframe for each session in sessions appended to list\n",
    "        for sess in sessions:\n",
    "            sess_df = filtered_data[filtered_data['Session ID'].isin(sess)]\n",
    "            choices = sess_df['Decision'].to_numpy().reshape(-1, 1).astype(int)\n",
    "            inpts = sess_df[x_cols].to_numpy()\n",
    "            sess_len = len(sess_df)\n",
    "            sess_list.append(sess_df)\n",
    "            test_choices.append(choices)\n",
    "            trials.append(sess_len)\n",
    "            test_inpts.append(inpts)        \n",
    "        test_ll = animal_models[i]['model_list'][j]['glmhmm'].log_likelihood(test_choices[j], test_inpts[j])\n",
    "        #normalize log likelihoods by number of trials\n",
    "        norm_ll = [test_ll/trials[j]]\n",
    "        animal_test_ll.append({'num_states': num_states, 'mouse': mouse['mouse'], 'norm_ll': norm_ll})\n",
    "\n",
    "#group data by mouse and then find delta NLL\n",
    "grouped_data = {}\n",
    "for item in animal_test_ll:\n",
    "    mouse = item['mouse']\n",
    "    if mouse not in grouped_data:\n",
    "        grouped_data[mouse] = []\n",
    "    grouped_data[mouse].append(item)\n",
    "    \n",
    "#Loop through each mouse and find the delta NLL in grouped_data\n",
    "animal_delta_ll_vals = []\n",
    "for mouse in grouped_data:\n",
    "    d_ll = []\n",
    "    # Extract the norm_ll value of the first item for reference\n",
    "    ref_norm_ll = grouped_data[mouse][0]['norm_ll']\n",
    "    for item in grouped_data[mouse]:\n",
    "        delta = ref_norm_ll[0] - item['norm_ll'][0]\n",
    "        d_ll.append(delta)\n",
    "    animal_delta_ll_vals.append({'mouse': mouse, 'delta_ll': d_ll})\n",
    "\n",
    "\n",
    "num_states_list = [1, 2, 3, 4]\n",
    "#Plot delta NLL for each mouse against number of states\n",
    "fig = plt.figure(figsize=(5, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "for i in range(len(animal_delta_ll_vals)):\n",
    "    plt.plot(num_states_list, animal_delta_ll_vals[i]['delta_ll'], marker = 'o', markersize = 5, lw=2)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"$\\Delta$NLL\", fontsize = 15)\n",
    "plt.xlabel(\"num_states\", fontsize = 15)\n",
    "plt.xticks(np.arange(1, 5))\n",
    "plt.title('Animal fits - normalized test LL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average delta NLL across each same index for each mouse\n",
    "avg_delta_ll = []\n",
    "for i in range(len(animal_delta_ll_vals[0]['delta_ll'])):\n",
    "    avg = np.mean([x['delta_ll'][i] for x in animal_delta_ll_vals])\n",
    "    avg_delta_ll.append(avg)\n",
    "\n",
    "#plot average delta NLL for each mouse with global delta NLL\n",
    "fig = plt.figure(figsize=(5, 5), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(num_states_list, avg_delta_ll, marker = 'o', markersize = 5, lw=2)\n",
    "plt.plot(num_states_list, delta_ll_vals_list, marker = 'o', markersize = 5, lw=2)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"$\\Delta$NLL\", fontsize = 15)\n",
    "plt.xlabel(\"num_states\", fontsize = 15)\n",
    "plt.xticks(np.arange(1, 5))\n",
    "plt.title('Average Animal fits vs global fits - normalized test LL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we will look at the Cross-validated log likelihoods for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare k states\n",
    "states = []\n",
    "scores ={'train': [], 'test': []}\n",
    "\n",
    "#loop through each global model and append train and test scores to list\n",
    "for item in global_models:\n",
    "    train_scores = item['model_train_scores'][0] \n",
    "    test_scores = item['model_test_scores'][0] \n",
    "    states.append(item['model_params']['num_states'][0])  \n",
    "    scores['train'].append(train_scores)\n",
    "    scores['test'].append(test_scores)\n",
    "\n",
    "qUtils.compare_k_states(scores, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare k states for animal fits\n",
    "\n",
    "states = []\n",
    "scores ={'train': [], 'test': []}\n",
    "\n",
    "for item in animal_models:\n",
    "    states.append(item['model_params']['num_states'][0])\n",
    "    for i in range(len(item['model_train_scores'])):\n",
    "        animal = item['model_train_scores'][i]['mouse']\n",
    "        train_scores = item['model_train_scores'][i]['scores']\n",
    "        scores['train'].append({'mouse': animal, 'num_states': item['model_params']['num_states'][0],\n",
    "                                 'score': train_scores})\n",
    "    for i in range(len(item['model_test_scores'])):\n",
    "        animal = item['model_test_scores'][i]['mouse']\n",
    "        test_scores = item['model_test_scores'][i]['scores']\n",
    "        scores['test'].append({'mouse': animal, 'num_states': item['model_params']['num_states'][0],\n",
    "                                 'score': test_scores})\n",
    "\n",
    "qUtils.compare_k_states(scores, states, multi_animal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict state sequences for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test data for each global model\n",
    "global_train_x = []\n",
    "global_test_x = []\n",
    "global_train_choices = []\n",
    "global_test_choices = []\n",
    "\n",
    "for i in range(len(global_models)):\n",
    "    x_cols = global_models[i]['model_params']['x_cols']\n",
    "    train_data = global_models[i]['data_splits']['train_ids']\n",
    "    test_data = global_models[i]['data_splits']['test_ids']\n",
    "    train_data = filtered_data[filtered_data['Session ID'].isin(train_data)]\n",
    "    test_data = filtered_data[filtered_data['Session ID'].isin(test_data)]\n",
    "    global_train_x.append(train_data[x_cols].to_numpy())\n",
    "    global_test_x.append(test_data[x_cols].to_numpy())\n",
    "    global_train_choices.append(train_data['Decision'].to_numpy().reshape(-1, 1).astype(int))\n",
    "    global_test_choices.append(test_data['Decision'].to_numpy().reshape(-1, 1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict state sequence for each global model\n",
    "global_train_states, global_test_states = qUtils.predict_state(global_train_x, global_test_x, \n",
    "                                                               global_train_choices, global_test_choices, \n",
    "                                                               global_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test data for each animal model\n",
    "animal_train_x = []\n",
    "animal_test_x = []\n",
    "animal_train_choices = []\n",
    "animal_test_choices = []\n",
    "\n",
    "for i in range(len(animal_models)):\n",
    "    x_cols = animal_models[i]['model_params']['x_cols']\n",
    "    for j, mouse in enumerate(animal_models[i]['model_list']):\n",
    "        animal = animal_models[i]['model_list'][j]['mouse']\n",
    "        num_states = animal_models[i]['model_params']['num_states'][0]\n",
    "        train_data = animal_models[i]['data_splits']['train_ids'][j]\n",
    "        test_data = animal_models[i]['data_splits']['test_ids'][j]\n",
    "        train_data = filtered_data[filtered_data['Session ID'].isin(train_data)]\n",
    "        test_data = filtered_data[filtered_data['Session ID'].isin(test_data)]\n",
    "        animal_train_x.append({'mouse': animal,'num_states': num_states, 'data': train_data[x_cols].to_numpy()})\n",
    "        animal_test_x.append({'mouse': animal,'num_states': num_states, 'data': test_data[x_cols].to_numpy()})\n",
    "        animal_train_choices.append({'mouse': animal,'num_states': num_states, 'data': train_data['Decision'].to_numpy().reshape(-1, 1).astype(int)})\n",
    "        animal_test_choices.append({'mouse': animal,'num_states': num_states, 'data': test_data['Decision'].to_numpy().reshape(-1, 1).astype(int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_train_states, animal_test_states = qUtils.predict_state(animal_train_x, animal_test_x, \n",
    "                                                               animal_train_choices, animal_test_choices, \n",
    "                                                               animal_models, multi_animal = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate prediction accuracy for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0 state(s) has a test predictive accuracy of 0.8578763382128032\n",
      "Model with 1 state(s) has a test predictive accuracy of 0.8600793824193431\n",
      "Model with 2 state(s) has a test predictive accuracy of 0.8553819823756463\n",
      "Model with 3 state(s) has a test predictive accuracy of 0.8530696963076251\n"
     ]
    }
   ],
   "source": [
    "global_acc = qUtils.predict_choice(global_models, global_test_states, global_test_x, global_test_choices, accuracy=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal Model AB with 1 state(s) has a test predictive accuracy of 0.8808748255002327\n",
      "Animal Model AN with 1 state(s) has a test predictive accuracy of 0.8478976234003657\n",
      "Animal Model AR with 1 state(s) has a test predictive accuracy of 0.8255072463768116\n",
      "Animal Model BB with 1 state(s) has a test predictive accuracy of 0.8940527766837337\n",
      "Animal Model BL with 1 state(s) has a test predictive accuracy of 0.8727064220183486\n",
      "Animal Model BN with 1 state(s) has a test predictive accuracy of 0.84\n",
      "Animal Model BR with 1 state(s) has a test predictive accuracy of 0.8613445378151261\n",
      "Animal Model CB with 1 state(s) has a test predictive accuracy of 0.8645245332175423\n",
      "Animal Model CL with 1 state(s) has a test predictive accuracy of 0.8989672204759767\n",
      "Animal Model CN with 1 state(s) has a test predictive accuracy of 0.910761154855643\n",
      "Animal Model CR with 1 state(s) has a test predictive accuracy of 0.861781848459617\n",
      "Animal Model FB with 1 state(s) has a test predictive accuracy of 0.8782948259030263\n",
      "Animal Model FL with 1 state(s) has a test predictive accuracy of 0.8210526315789474\n",
      "Animal Model FN with 1 state(s) has a test predictive accuracy of 0.8396537510305029\n",
      "Animal Model FR with 1 state(s) has a test predictive accuracy of 0.8783730934689089\n",
      "Animal Model GB with 1 state(s) has a test predictive accuracy of 0.8936495791889824\n",
      "Animal Model GL with 1 state(s) has a test predictive accuracy of 0.9217305151915456\n",
      "Animal Model GN with 1 state(s) has a test predictive accuracy of 0.9057569296375266\n",
      "Animal Model GR with 1 state(s) has a test predictive accuracy of 0.9368907131862494\n",
      "Animal Model HB with 1 state(s) has a test predictive accuracy of 0.9003159003159004\n",
      "Animal Model HL with 1 state(s) has a test predictive accuracy of 0.8970769864141622\n",
      "Animal Model HN with 1 state(s) has a test predictive accuracy of 0.8805544231553201\n",
      "Animal Model HR with 1 state(s) has a test predictive accuracy of 0.8823792486583184\n",
      "Animal Model MB with 1 state(s) has a test predictive accuracy of 0.8548241659152389\n",
      "Animal Model ML with 1 state(s) has a test predictive accuracy of 0.8071065989847716\n",
      "Animal Model MN with 1 state(s) has a test predictive accuracy of 0.8385826771653543\n",
      "Animal Model MR with 1 state(s) has a test predictive accuracy of 0.8194444444444444\n",
      "Animal Model YB with 1 state(s) has a test predictive accuracy of 0.846309403437816\n",
      "Animal Model YL with 1 state(s) has a test predictive accuracy of 0.9033989266547406\n",
      "Animal Model YN with 1 state(s) has a test predictive accuracy of 0.8433179723502304\n",
      "Animal Model YR with 1 state(s) has a test predictive accuracy of 0.8865461847389559\n",
      "Animal Model AB with 2 state(s) has a test predictive accuracy of 0.8385542168674699\n",
      "Animal Model AN with 2 state(s) has a test predictive accuracy of 0.8257183231276496\n",
      "Animal Model AR with 2 state(s) has a test predictive accuracy of 0.7905454545454546\n",
      "Animal Model BB with 2 state(s) has a test predictive accuracy of 0.8515704154002026\n",
      "Animal Model BL with 2 state(s) has a test predictive accuracy of 0.8417954378219279\n",
      "Animal Model BN with 2 state(s) has a test predictive accuracy of 0.8675282714054927\n",
      "Animal Model BR with 2 state(s) has a test predictive accuracy of 0.8270096463022508\n",
      "Animal Model CB with 2 state(s) has a test predictive accuracy of 0.815416885159937\n",
      "Animal Model CL with 2 state(s) has a test predictive accuracy of 0.8130148270181219\n",
      "Animal Model CN with 2 state(s) has a test predictive accuracy of 0.8883626522327469\n",
      "Animal Model CR with 2 state(s) has a test predictive accuracy of 0.835592221567472\n",
      "Animal Model FB with 2 state(s) has a test predictive accuracy of 0.8681858802502234\n",
      "Animal Model FL with 2 state(s) has a test predictive accuracy of 0.7683194383501536\n",
      "Animal Model FN with 2 state(s) has a test predictive accuracy of 0.8\n",
      "Animal Model FR with 2 state(s) has a test predictive accuracy of 0.8107403545359749\n",
      "Animal Model GB with 2 state(s) has a test predictive accuracy of 0.8720588235294118\n",
      "Animal Model GL with 2 state(s) has a test predictive accuracy of 0.8726575809199318\n",
      "Animal Model GN with 2 state(s) has a test predictive accuracy of 0.8797917652626597\n",
      "Animal Model GR with 2 state(s) has a test predictive accuracy of 0.8022339027595269\n",
      "Animal Model HB with 2 state(s) has a test predictive accuracy of 0.8702757916241062\n",
      "Animal Model HL with 2 state(s) has a test predictive accuracy of 0.8645418326693227\n",
      "Animal Model HN with 2 state(s) has a test predictive accuracy of 0.85260663507109\n",
      "Animal Model HR with 2 state(s) has a test predictive accuracy of 0.8506010303377218\n",
      "Animal Model MB with 2 state(s) has a test predictive accuracy of 0.8865323435843054\n",
      "Animal Model ML with 2 state(s) has a test predictive accuracy of 0.8481481481481481\n",
      "Animal Model MN with 2 state(s) has a test predictive accuracy of 0.863225806451613\n",
      "Animal Model MR with 2 state(s) has a test predictive accuracy of 0.793918918918919\n",
      "Animal Model YB with 2 state(s) has a test predictive accuracy of 0.8463796477495108\n",
      "Animal Model YL with 2 state(s) has a test predictive accuracy of 0.8843601895734597\n",
      "Animal Model YN with 2 state(s) has a test predictive accuracy of 0.8442622950819673\n",
      "Animal Model YR with 2 state(s) has a test predictive accuracy of 0.8579743888242142\n",
      "Animal Model AB with 3 state(s) has a test predictive accuracy of 0.8994059405940594\n",
      "Animal Model AN with 3 state(s) has a test predictive accuracy of 0.8573949876456054\n",
      "Animal Model AR with 3 state(s) has a test predictive accuracy of 0.8610515021459227\n",
      "Animal Model BB with 3 state(s) has a test predictive accuracy of 0.8966642494561277\n",
      "Animal Model BL with 3 state(s) has a test predictive accuracy of 0.8899233296823659\n",
      "Animal Model BN with 3 state(s) has a test predictive accuracy of 0.8495440729483282\n",
      "Animal Model BR with 3 state(s) has a test predictive accuracy of 0.8926204153778171\n",
      "Animal Model CB with 3 state(s) has a test predictive accuracy of 0.8338919925512104\n",
      "Animal Model CL with 3 state(s) has a test predictive accuracy of 0.9235867446393762\n",
      "Animal Model CN with 3 state(s) has a test predictive accuracy of 0.8878116343490304\n",
      "Animal Model CR with 3 state(s) has a test predictive accuracy of 0.8737226277372263\n",
      "Animal Model FB with 3 state(s) has a test predictive accuracy of 0.8641607740975065\n",
      "Animal Model FL with 3 state(s) has a test predictive accuracy of 0.7860836859426422\n",
      "Animal Model FN with 3 state(s) has a test predictive accuracy of 0.8778571428571429\n",
      "Animal Model FR with 3 state(s) has a test predictive accuracy of 0.8488142292490118\n",
      "Animal Model GB with 3 state(s) has a test predictive accuracy of 0.8911711711711712\n",
      "Animal Model GL with 3 state(s) has a test predictive accuracy of 0.9081044421837912\n",
      "Animal Model GN with 3 state(s) has a test predictive accuracy of 0.9163481953290871\n",
      "Animal Model GR with 3 state(s) has a test predictive accuracy of 0.9748168498168498\n",
      "Animal Model HB with 3 state(s) has a test predictive accuracy of 0.8984490398818316\n",
      "Animal Model HL with 3 state(s) has a test predictive accuracy of 0.867816091954023\n",
      "Animal Model HN with 3 state(s) has a test predictive accuracy of 0.8774834437086093\n",
      "Animal Model HR with 3 state(s) has a test predictive accuracy of 0.8798758865248227\n",
      "Animal Model MB with 3 state(s) has a test predictive accuracy of 0.847424684159378\n",
      "Animal Model ML with 3 state(s) has a test predictive accuracy of 0.8337531486146096\n",
      "Animal Model MN with 3 state(s) has a test predictive accuracy of 0.8338235294117647\n",
      "Animal Model MR with 3 state(s) has a test predictive accuracy of 0.795045045045045\n",
      "Animal Model YB with 3 state(s) has a test predictive accuracy of 0.8350202429149798\n",
      "Animal Model YL with 3 state(s) has a test predictive accuracy of 0.90437890974084\n",
      "Animal Model YN with 3 state(s) has a test predictive accuracy of 0.7882483370288248\n",
      "Animal Model YR with 3 state(s) has a test predictive accuracy of 0.8633177570093458\n",
      "Animal Model AB with 4 state(s) has a test predictive accuracy of 0.8307228915662651\n",
      "Animal Model AN with 4 state(s) has a test predictive accuracy of 0.8214790390956194\n",
      "Animal Model AR with 4 state(s) has a test predictive accuracy of 0.7890909090909091\n",
      "Animal Model BB with 4 state(s) has a test predictive accuracy of 0.851063829787234\n",
      "Animal Model BL with 4 state(s) has a test predictive accuracy of 0.8462104488594555\n",
      "Animal Model BN with 4 state(s) has a test predictive accuracy of 0.8683360258481422\n",
      "Animal Model BR with 4 state(s) has a test predictive accuracy of 0.8263665594855305\n",
      "Animal Model CB with 4 state(s) has a test predictive accuracy of 0.8180388044048243\n",
      "Animal Model CL with 4 state(s) has a test predictive accuracy of 0.8064250411861614\n",
      "Animal Model CN with 4 state(s) has a test predictive accuracy of 0.8768606224627875\n",
      "Animal Model CR with 4 state(s) has a test predictive accuracy of 0.8432527990571597\n",
      "Animal Model FB with 4 state(s) has a test predictive accuracy of 0.868632707774799\n",
      "Animal Model FL with 4 state(s) has a test predictive accuracy of 0.7362878455462922\n",
      "Animal Model FN with 4 state(s) has a test predictive accuracy of 0.7719298245614035\n",
      "Animal Model FR with 4 state(s) has a test predictive accuracy of 0.8206465067778936\n",
      "Animal Model GB with 4 state(s) has a test predictive accuracy of 0.8607843137254902\n",
      "Animal Model GL with 4 state(s) has a test predictive accuracy of 0.8722316865417377\n",
      "Animal Model GN with 4 state(s) has a test predictive accuracy of 0.8788452437292948\n",
      "Animal Model GR with 4 state(s) has a test predictive accuracy of 0.828515111695138\n",
      "Animal Model HB with 4 state(s) has a test predictive accuracy of 0.8697650663942799\n",
      "Animal Model HL with 4 state(s) has a test predictive accuracy of 0.8630478087649402\n",
      "Animal Model HN with 4 state(s) has a test predictive accuracy of 0.8502369668246446\n",
      "Animal Model HR with 4 state(s) has a test predictive accuracy of 0.8437321121923297\n",
      "Animal Model MB with 4 state(s) has a test predictive accuracy of 0.8769883351007424\n",
      "Animal Model ML with 4 state(s) has a test predictive accuracy of 0.828395061728395\n",
      "Animal Model MN with 4 state(s) has a test predictive accuracy of 0.7677419354838709\n",
      "Animal Model MR with 4 state(s) has a test predictive accuracy of 0.8063063063063063\n",
      "Animal Model YB with 4 state(s) has a test predictive accuracy of 0.8238747553816047\n",
      "Animal Model YL with 4 state(s) has a test predictive accuracy of 0.885308056872038\n",
      "Animal Model YN with 4 state(s) has a test predictive accuracy of 0.8489461358313818\n",
      "Animal Model YR with 4 state(s) has a test predictive accuracy of 0.869615832363213\n"
     ]
    }
   ],
   "source": [
    "animal_acc = qUtils.predict_choice(animal_models, animal_test_states, animal_test_x, animal_test_choices, accuracy=True, verbose=True, multi_animal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sabatini-glm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
